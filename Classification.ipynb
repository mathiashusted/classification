{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff690c28-a5cd-4ddb-a9d5-5f71c4c05e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b986094a-2011-4fdb-829e-00c077c94603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # First convolutional layer: 3 input channels (RGB), outputs 16 channels\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        # Flatten output of the convolutional layers\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b78ea0-5f53-4cef-8ea1-830d745e3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[-0.0874,  0.0153, -0.0624,  0.0414, -0.0396, -0.0955, -0.0510,  0.0430,\n",
      "         -0.0859, -0.0748]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create instance\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# Random data for testing\n",
    "random_test = torch.rand((1, 3, 32, 32))\n",
    "\n",
    "result = model(random_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fe27c0-a907-4972-aee2-1f77976ff920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAR_SPLIT = 1 - TRAIN_SPLIT\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af3158c-f4b7-4a10-94fa-875f467bda30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformation?\n",
    "\n",
    "# Load data\n",
    "\n",
    "fullTrainingSet = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# We'll split our training set into 80% training, 20% validation set\n",
    "\n",
    "trainingSize = int(0.8 * len(fullTrainingSet))\n",
    "valSize = len(fullTrainingSet) - trainingSize\n",
    "trainset, valset = torch.utils.data.random_split(fullTrainingSet, [trainingSize, valSize])\n",
    "\n",
    "# Load the test set\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "trainSteps = len(trainloader.dataset) // BATCH_SIZE\n",
    "testSteps = len(testloader.dataset) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc57aa2-37db-461a-b10e-b3cf856caf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting epoch 1/10\n",
      "Epoch 1 complete\n",
      "Loss: 0.8791881799697876\n",
      "Accuracy: 0.68955\n",
      "Validation loss: 0.2335376739501953\n",
      "Validation accuracy: 0.168425\n",
      "\n",
      "Starting epoch 2/10\n",
      "Epoch 2 complete\n",
      "Loss: 0.8223723769187927\n",
      "Accuracy: 0.71065\n",
      "Validation loss: 0.22199738025665283\n",
      "Validation accuracy: 0.172625\n",
      "\n",
      "Starting epoch 3/10\n",
      "Epoch 3 complete\n",
      "Loss: 0.7705252170562744\n",
      "Accuracy: 0.727875\n",
      "Validation loss: 0.22818176448345184\n",
      "Validation accuracy: 0.17055\n",
      "\n",
      "Starting epoch 4/10\n",
      "Epoch 4 complete\n",
      "Loss: 0.7259247303009033\n",
      "Accuracy: 0.745\n",
      "Validation loss: 0.22352515161037445\n",
      "Validation accuracy: 0.17225\n",
      "\n",
      "Starting epoch 5/10\n",
      "Epoch 5 complete\n",
      "Loss: 0.6825100779533386\n",
      "Accuracy: 0.761425\n",
      "Validation loss: 0.213173970580101\n",
      "Validation accuracy: 0.17715\n",
      "\n",
      "Starting epoch 6/10\n",
      "Epoch 6 complete\n",
      "Loss: 0.651515543460846\n",
      "Accuracy: 0.770125\n",
      "Validation loss: 0.21549057960510254\n",
      "Validation accuracy: 0.1775\n",
      "\n",
      "Starting epoch 7/10\n",
      "Epoch 7 complete\n",
      "Loss: 0.6114392876625061\n",
      "Accuracy: 0.785075\n",
      "Validation loss: 0.21738344430923462\n",
      "Validation accuracy: 0.1775\n",
      "\n",
      "Starting epoch 8/10\n",
      "Epoch 8 complete\n",
      "Loss: 0.5697643756866455\n",
      "Accuracy: 0.79845\n",
      "Validation loss: 0.22636842727661133\n",
      "Validation accuracy: 0.176725\n",
      "\n",
      "Starting epoch 9/10\n",
      "Epoch 9 complete\n",
      "Loss: 0.5417287349700928\n",
      "Accuracy: 0.8068\n",
      "Validation loss: 0.2390141636133194\n",
      "Validation accuracy: 0.172225\n",
      "\n",
      "Starting epoch 10/10\n",
      "Epoch 10 complete\n",
      "Loss: 0.5037293434143066\n",
      "Accuracy: 0.823275\n",
      "Validation loss: 0.2304028570652008\n",
      "Validation accuracy: 0.1756\n",
      "\n",
      "Training finished in 133.91299414634705s, starting validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.94      0.81      0.87      3974\n",
      "  automobile       0.96      0.92      0.94      4041\n",
      "        bird       0.85      0.71      0.77      4020\n",
      "         cat       0.64      0.79      0.71      3992\n",
      "        deer       0.77      0.84      0.80      3975\n",
      "         dog       0.81      0.67      0.74      3992\n",
      "        frog       0.81      0.93      0.86      3987\n",
      "       horse       0.89      0.90      0.89      4036\n",
      "        ship       0.96      0.88      0.92      3956\n",
      "       truck       0.87      0.94      0.90      4027\n",
      "\n",
      "    accuracy                           0.84     40000\n",
      "   macro avg       0.85      0.84      0.84     40000\n",
      "weighted avg       0.85      0.84      0.84     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More parameters\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=INIT_LR)\n",
    "\n",
    "lossF = nn.CrossEntropyLoss()\n",
    "\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "startTime = time.time()\n",
    "\n",
    "for e in range(0, EPOCHS):\n",
    "    print(f\"Starting epoch {e+1}/{EPOCHS}\")\n",
    "    model.train()\n",
    "\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "\n",
    "    for (x, y) in trainloader:\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = lossF(pred, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for (x, y) in valloader:\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            \n",
    "            pred = model(x)\n",
    "            \n",
    "            totalValLoss += lossF(pred, y)\n",
    "            valCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / testSteps\n",
    "\n",
    "    trainCorrect /= len(trainloader.dataset)\n",
    "    valCorrect /= len(testloader.dataset)\n",
    "\n",
    "    # Todo: Update history\n",
    "\n",
    "    print(f\"Epoch {e + 1} complete\\nLoss: {avgTrainLoss}\\nAccuracy: {trainCorrect}\\nValidation loss: {avgValLoss}\\nValidation accuracy: {valCorrect}\\n\")\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "print(f\"Training finished in {endTime-startTime}s, starting validation\")\n",
    "\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "\n",
    "    for (image, label) in testloader:\n",
    "        image = image.to(device)\n",
    "        \n",
    "        pred = model(image)\n",
    "        preds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "        targets.extend(label.cpu().numpy())\n",
    "\n",
    "print(classification_report(targets, preds, target_names=testset.classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
